{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export flux data over sites\n",
    "- This script is used to export flux data for Taylor diagram;\n",
    "- Simulations: CNTL, WRF_LCZ, LI_LCZ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cftime\n",
    "import string\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/mnt/iusers01/fatpou01/sees01/a16404ys/scratch/'\n",
    "archive = '/Projects/archive/0project2/'\n",
    "psites = [\"AU-Preston\",\"AU-SurreyHills\",\"CA-Sunset\",\"FI-Kumpula\",\"FI-Torni\",\n",
    "          \"FR-Capitole\",\"GR-HECKOR\",\"JP-Yoyogi\",\"KR-Jungnang\",\"KR-Ochang\",\n",
    "          \"MX-Escandon\",\"NL-Amsterdam\",\"PL-Lipowa\",\"PL-Narutowicza\",\"SG-TelokKurau06\",\n",
    "          \"UK-KingsCollege\",\"UK-Swindon\",\"US-Baltimore\",\"US-Minneapolis1\",\"US-Minneapolis2\",\n",
    "          \"US-WestPhoenix\"]\n",
    "msites = [\"AU-Pre\",\"AU-Sur\",\"CA-Sun\",\"FI-Kum\",\"FI-Tor\",\n",
    "          \"FR-Cap\",\"GR-HEC\",\"JP-Yoy\",\"KR-Jun\",\"KR-Och\",\n",
    "          \"MX-Esc\",\"NL-Ams\",\"PL-Lip\",\"PL-Nar\",\"SG-Tel\",\n",
    "          \"UK-Kin\",\"UK-Swi\",\"US-Bal\",\"US-Mi1\",\"US-Mi2\",\n",
    "          \"US-Wes\"]\n",
    "\n",
    "START = ['1993', '1994', '2002', '2000', '2000',\n",
    "        '1994', '2009', '2006', '2007', '2005', \n",
    "        '2001', '2009', '1998', '1998', '1996', \n",
    "        '2002', '2001', '1992', '1996', '1996', \n",
    "        '2001']\n",
    "END = ['2004', '2004', '2016', '2013', '2013',\n",
    "       '2005', '2020', '2020', '2019', '2017', \n",
    "       '2012', '2020',  '2012', '2012', '2007', \n",
    "       '2014', '2013',  '2007', '2009', '2009',   \n",
    "       '2013']\n",
    "var0 = ['LWdown', 'SWdown']\n",
    "var1 = ['LWdown', 'SWdown','LWup', 'SWup', 'Qh', 'Qle', 'Qtau']\n",
    "var2 = ['FIRE_U', 'FSR', 'FSH_U', 'EFLX_LH_TOT_U', 'TAUX']\n",
    "zone = [10, 10, -8, 2, 2, \n",
    "        1, 2, 9, 9, 9, \n",
    "        -6, 1, 1, 1, 8, \n",
    "        0, 0, -5, -6, -6, \n",
    "        -7]\n",
    "start_date = ['2003-08-12T03:30:00', '2004-02-23T05:00:00', '2012-01-01T00:00:00', '2010-12-31T22:30:00', '2010-12-31T22:30:00',\n",
    "              '2004-02-20T00:30:00', '2019-06-30T22:00:00', '2016-03-31T15:00:00', '2017-01-24T16:00:00', '2015-06-07T15:00:00',\n",
    "              '2011-06-01T17:00:00', '2019-01-01T00:00:00', '2008-01-01T00:00:00', '2008-01-01T00:00:00', '2006-04-30T16:30:00',\n",
    "              '2012-04-04T00:00:00', '2011-05-11T19:00:00', '2002-01-01T05:00:00', '2006-06-01T18:00:00', '2006-06-01T18:00:00',\n",
    "              '2011-12-16T18:30:00']\n",
    "\n",
    "end_date = ['2004-11-28T11:30:00', '2004-07-19T22:00:00', '2016-12-31T22:00:00', '2013-12-31T20:30:00', '2013-12-31T20:30:00',\n",
    "            '2005-02-28T22:30:00', '2020-06-30T20:00:00', '2020-03-31T11:00:00', '2019-04-29T05:00:00', '2017-07-26T00:00:00',\n",
    "            '2012-09-13T12:30:00', '2020-10-13T08:30:00', '2012-12-31T20:00:00', '2012-12-31T20:00:00', '2007-03-31T14:30:00',\n",
    "            '2013-12-31T21:00:00', '2013-04-25T08:00:00', '2007-01-01T01:00:00', '2009-05-29T11:30:00', '2008-01-01T00:00:00',\n",
    "            '2013-01-01T05:00:00']\n",
    "'''\n",
    "mid_date = ['2004-01-01 00:00:00', '2004-05-01 00:00:00', '2014-01-01 00:00:00', '2012-01-01 00:00:00', '2012-01-01 00:00:00',\n",
    "            '2004-09-01T00:00:00', '2020-01-01T00:00:00', '2018-01-01T00:00:00', '2018-01-01T00:00:00', '2016-01-01T00:00:00',\n",
    "            '2012-01-01T00:00:00', '2020-01-01T00:00:00', '2010-01-01T00:00:00', '2010-01-01T00:00:00', '2007-01-01T00:00:00',\n",
    "            '2013-01-01T00:00:00', '2012-01-01T00:00:00', '2004-01-01T00:00:00', '2008-01-01T00:00:00', '2009-05-29T11:30:00',\n",
    "            '2012-06-01T00:00:00']\n",
    "'''\n",
    "mid_date = [['2004-01-01 00:00:00', '2004-06-01 00:00:00'], ['2004-06-01 00:00:00', '2004-09-01 00:00:00'], ['2014-01-01 00:00:00'], ['2012-01-01 00:00:00', '2013-01-01 00:00:00'], ['2012-01-01 00:00:00', '2013-01-01 00:00:00'],\n",
    "            ['2004-06-01T00:00:00', '2004-12-01T00:00:00'], ['2020-01-01T00:00:00'], ['2018-01-01T00:00:00'], ['2018-01-01T00:00:00'], ['2016-01-01T00:00:00', '2017-01-01T00:00:00'],\n",
    "            ['2012-01-01T00:00:00'], ['2020-01-01T00:00:00'], ['2010-01-01T00:00:00'], ['2010-01-01T00:00:00'], ['2006-09-01T00:00:00', '2007-01-01T00:00:00'],\n",
    "            ['2013-01-01T00:00:00'], ['2012-01-01T00:00:00', '2012-09-01T00:00:00'], ['2004-01-01T00:00:00'], ['2008-01-01T00:00:00'], ['2007-01-01T00:00:00'],\n",
    "            ['2012-06-01T00:00:00']]\n",
    "sequence = ['Rn', 'SWup', 'LWup', 'Qh', 'Qle', 'Qtau']\n",
    "sequence2 = ['$R_{n}$', '$SW_{up}$', '$LW_{up}$', '$Q_{h}$', '$Q_{le}$', '$Q_{tau}$']\n",
    "entity = ['obs', 'def', 'wrflcz', 'lilcz']\n",
    "label1 = ['Observation: mean', \n",
    "          'CNTL: mean', \n",
    "          'WRF_LCZ: mean', \n",
    "          'LI_LCZ: mean']\n",
    "label2 = ['Observation: 5-95% range', \n",
    "          'CNTL: 5-95% range', \n",
    "          'WRF_LCZ: 5-95% range', \n",
    "          'LI_LCZ: 5-95% range']\n",
    "lc0 = '#083550'\n",
    "lc1 = '#006bac'\n",
    "lc2 = '#3da4e3'\n",
    "lc3 = '#6c64d4'\n",
    "lc = [lc0, lc1, lc2, lc3]\n",
    "alpha = [0.2, 0.15, 0.1, 0.1]\n",
    "labelfont = 6\n",
    "linewidth = 0.5\n",
    "labelcolor = '#6b6b6b'\n",
    "padding = 4\n",
    "metric = ['7-day mean', 'Diurnal mean']\n",
    "pad = 1\n",
    "xwidth = 0.5\n",
    "length = 2\n",
    "handletextpad = 0.5\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true - y_pred) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation with normalization, ref: https://projectpythia.org/advanced-viz-cookbook/notebooks/taylor-diagrams.html\n",
    "def calculate_metrics(observed_valid, *simulated):\n",
    "    metrics = []\n",
    "    for sim_data_valid in simulated:\n",
    "        # Remove NaN values from observed and simulated data\n",
    "    \n",
    "        # Standard deviation\n",
    "        std = float(np.std(sim_data_valid))\n",
    "        sdev = std/float(np.std(observed_valid))\n",
    "        \n",
    "        # Correlation coefficient\n",
    "        coef = float(xr.corr(xr.DataArray(observed_valid), xr.DataArray(sim_data_valid)).values)\n",
    "   \n",
    "        metrics.append((sdev, coef))\n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ['obs', 'def', 'wrflcz', 'lilcz']\n",
    "modelname = ['Observation', 'S-CNTL', 'S-WRF_LCZ', 'S-LI_LCZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "for sitesequence in range(len(psites)):\n",
    "#for sitesequence in [10]:\n",
    "    if sitesequence in [3, 4, 7, 8, 9, 12, 13, 14]:\n",
    "        var_saved = ['Rn', 'SWup', 'LWup','Qh', 'Qle']\n",
    "    elif sitesequence in [10]:\n",
    "        var_saved = ['Rn','SWup', 'Qh', 'Qle', 'Qtau']\n",
    "    else:    \n",
    "        var_saved = ['Rn', 'SWup', 'LWup', 'Qh', 'Qle', 'Qtau'] \n",
    "    \n",
    "    GRIDNAME = psites[sitesequence]\n",
    "    GRIDNAME_single = msites[sitesequence]\n",
    "    START_year = START[sitesequence]\n",
    "    time_zone = zone[sitesequence] \n",
    "    start_time = start_date[sitesequence]\n",
    "    end_time = end_date[sitesequence]\n",
    "    mid_time = mid_date[sitesequence]\n",
    "    \n",
    "    datm = path + 'UrbanPlumber/datm_files/'+ GRIDNAME_single + '/CLM1PT_data/CTSM_DATM_' + GRIDNAME_single + '_' + START[sitesequence] + '-' + END[sitesequence] + '.nc'\n",
    "    ds_datm = xr.open_dataset(datm)\n",
    "    \n",
    "    # observation = path + 'UrbanPlumber/Urban-PLUMBER_FullCollection_v1/' + GRIDNAME + '/timeseries/'+ GRIDNAME + '_raw_observations_v1.nc'\n",
    "    observation = path + 'UrbanPlumber/Urban-PLUMBER_FullCollection_v1/' + GRIDNAME + '/timeseries/'+ GRIDNAME + '_clean_observations_v1.nc'\n",
    "    ds_ob = xr.open_dataset(observation)\n",
    "\n",
    "    keith = path + archive + GRIDNAME_single + '_def/lnd/hist/' + GRIDNAME_single + '_def.clm2.h0.' + START_year +'-01-01-00000.nc'\n",
    "    ds_ko = xr.open_dataset(keith)\n",
    "    \n",
    "    wrf = path + archive + '0sp/' + GRIDNAME_single + '_wrf_all_new/lnd/hist/' + GRIDNAME_single + '_wrf_all_new.clm2.h0.' + START_year +'-01-01-00000.nc'\n",
    "    ds_wrf = xr.open_dataset(wrf)\n",
    "    \n",
    "    li = path +  archive + '0sp/' + GRIDNAME_single + '_li_all/lnd/hist/' + GRIDNAME_single + '_li_all.clm2.h0.' + START_year +'-01-01-00000.nc'\n",
    "    ds_li = xr.open_dataset(li)\n",
    "\n",
    "    ds_wrf['time']=ds_wrf['time'].dt.round('min')\n",
    "    ds_wrf['time']=ds_wrf['time'].dt.ceil('min')\n",
    "    ds_li['time']=ds_li['time'].dt.round('min')\n",
    "    ds_li['time']=ds_li['time'].dt.ceil('min')\n",
    "    ds_ko['time']=ds_ko['time'].dt.round('min')\n",
    "    ds_ko['time']=ds_ko['time'].dt.ceil('min')\n",
    "    \n",
    "    sliced_ds_datm = ds_datm.sel(time=slice(start_time, end_time))[var0]\n",
    "    df_datm = sliced_ds_datm.to_dataframe().reset_index()\n",
    "\n",
    "    sliced_ds_ko = ds_ko.sel(time=slice(start_time, end_time))[var2]\n",
    "    df_ko = sliced_ds_ko.to_dataframe().reset_index()\n",
    "    df_ko.drop(columns=['lndgrid'], inplace=True)\n",
    "    df_ko = df_ko.rename(columns={'FIRE_U': 'LWup_def', 'FSR': 'SWup_def','FSH_U': 'Qh_def', 'EFLX_LH_TOT_U': 'Qle_def', 'TAUX': 'Qtau_def'})\n",
    "    df_ko['Qtau_def'] = - df_ko['Qtau_def']\n",
    "    df_ko['Rn_def'] = df_datm['LWdown'] + df_datm['SWdown'] - df_ko['SWup_def'] - df_ko['LWup_def']\n",
    "    \n",
    "    sliced_ds_wrf = ds_wrf.sel(time=slice(start_time, end_time))[var2]\n",
    "    df_wrf = sliced_ds_wrf.to_dataframe().reset_index()\n",
    "    df_wrf.drop(columns=['lndgrid'], inplace=True)\n",
    "    df_wrf = df_wrf.rename(columns={'FIRE_U': 'LWup_wrflcz', 'FSR': 'SWup_wrflcz','FSH_U': 'Qh_wrflcz', 'EFLX_LH_TOT_U': 'Qle_wrflcz', 'TAUX': 'Qtau_wrflcz'})\n",
    "    df_wrf['Qtau_wrflcz'] = - df_wrf['Qtau_wrflcz']\n",
    "    df_wrf['Rn_wrflcz'] = df_datm['LWdown'] + df_datm['SWdown'] - df_wrf['SWup_wrflcz'] - df_wrf['LWup_wrflcz']\n",
    "    \n",
    "    sliced_ds_li = ds_li.sel(time=slice(start_time, end_time))[var2]\n",
    "    df_li = sliced_ds_li.to_dataframe().reset_index()\n",
    "    df_li.drop(columns=['lndgrid'], inplace=True)\n",
    "    df_li = df_li.rename(columns={'FIRE_U': 'LWup_lilcz', 'FSR': 'SWup_lilcz','FSH_U': 'Qh_lilcz', 'EFLX_LH_TOT_U': 'Qle_lilcz', 'TAUX': 'Qtau_lilcz'})\n",
    "    df_li['Qtau_lilcz'] = - df_li['Qtau_lilcz']\n",
    "    df_li['Rn_lilcz'] = df_datm['LWdown'] + df_datm['SWdown'] - df_li['SWup_lilcz'] - df_li['LWup_lilcz']\n",
    "    \n",
    "    if sitesequence in [3, 4, 7, 8, 9, 12, 13, 14]:\n",
    "        sliced_ds_ob = ds_ob.sel(time=slice(start_time, end_time))[['LWdown', 'SWdown','LWup', 'SWup', 'Qh', 'Qle']]\n",
    "        df_ob = sliced_ds_ob.to_dataframe().reset_index()\n",
    "        df_ob = df_ob.rename(columns={'LWdown': 'LWdown_obs', \n",
    "                                      'SWdown': 'SWdown_obs',\n",
    "                                      'LWup': 'LWup_obs', \n",
    "                                      'SWup': 'SWup_obs',\n",
    "                                      'Qh': 'Qh_obs', \n",
    "                                      'Qle': 'Qle_obs'})\n",
    "        df_ob['Qtau_obs'] = np.nan\n",
    "        \n",
    "    else: \n",
    "        sliced_ds_ob = ds_ob.sel(time=slice(start_time, end_time))[var1]\n",
    "        df_ob = sliced_ds_ob.to_dataframe().reset_index()\n",
    "        df_ob = df_ob.rename(columns={'LWdown': 'LWdown_obs', \n",
    "                                      'SWdown': 'SWdown_obs',\n",
    "                                      'LWup': 'LWup_obs', \n",
    "                                      'SWup': 'SWup_obs',\n",
    "                                      'Qh': 'Qh_obs', \n",
    "                                      'Qle': 'Qle_obs', \n",
    "                                      'Qtau': 'Qtau_obs'})\n",
    "    df_ob['Rn_obs'] = df_ob['LWdown_obs'] + df_ob['SWdown_obs']-df_ob['SWup_obs']-df_ob['LWup_obs']\n",
    "    \n",
    "    df = pd.merge(df_ob, df_ko, on='time').merge(df_wrf, on='time').merge(df_li, on='time')\n",
    "    df.loc[df['LWup_obs'].isna(), ['LWup_wrflcz', 'LWup_lilcz','LWup_def',\n",
    "                                  'Rn_obs', 'Rn_wrflcz', 'Rn_lilcz', 'Rn_def']] = np.nan\n",
    "    df.loc[df['SWup_obs'].isna(), ['SWup_wrflcz', 'SWup_lilcz', 'SWup_def',\n",
    "                                  'Rn_obs', 'Rn_wrflcz', 'Rn_lilcz', 'Rn_def']] = np.nan\n",
    "    df.loc[df['Qle_obs'].isna(), ['Qle_wrflcz', 'Qle_lilcz','Qle_def']] = np.nan\n",
    "    df.loc[df['Qh_obs'].isna(), ['Qh_wrflcz', 'Qh_lilcz','Qh_def']] = np.nan\n",
    "    df.loc[df['Qtau_obs'].isna(), ['Qtau_wrflcz', 'Qtau_lilcz','Qtau_def']] = np.nan\n",
    "    results = []\n",
    "    \n",
    "    for i in range(len(var_saved)):    \n",
    "        var_obs = var_saved[i] + '_' + model[0]\n",
    "        var_def = var_saved[i] + '_' + model[1]\n",
    "        var_wrflcz = var_saved[i] + '_' + model[2]\n",
    "        var_lilcz = var_saved[i] + '_' + model[3]\n",
    "        observed_data = df[var_obs]\n",
    "        simulated_data = [df[var_def], df[var_wrflcz], df[var_lilcz]]\n",
    "        metrics = calculate_metrics(observed_data, *simulated_data)\n",
    "        \n",
    "        for j, (sdev, coef) in enumerate(metrics):\n",
    "            results.append({\n",
    "                'Variable': var_saved[i],\n",
    "                'Model': modelname[j+1],\n",
    "                'sdev': sdev,\n",
    "                #'rmse': rmse,\n",
    "                'coef': coef,\n",
    "                #'rms': rms,\n",
    "                #'bias': bias,\n",
    "                'site': GRIDNAME\n",
    "            })\n",
    "    all_results.extend(results) \n",
    "    \n",
    "results_df = pd.DataFrame(all_results)\n",
    "output_dir = '/mnt/iusers01/fatpou01/sees01/a16404ys/scratch/output_analysis/project2/sp/taylor_assess/'\n",
    "results_df.to_csv(output_dir + 'results4taylor.csv', index=False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
